{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c114966-e165-438c-8bcd-3900510228f2",
   "metadata": {},
   "source": [
    "# Data_Preprocessing_Balanced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce282bd0-5a83-4b9c-9791-98ae6112f565",
   "metadata": {},
   "source": [
    "## Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0343766-0417-4ec9-82fd-dc8a05506a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt # For optional plotting during EDA, can be commented out\n",
    "import seaborn as sns         # For optional plotting during EDA, can be commented out\n",
    "from sklearn.utils import resample # For undersampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e55bd32-89ae-4059-a809-0dbf4f490d84",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd3fc4d3-6d5d-4c89-8f9a-fb32857f9744",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_ROWS_TO_LOAD = 100000  # Load 100k rows from raw data\n",
    "CSV_FILE_PATH = \"brewery_data_complete_extended.csv\"\n",
    "OUTPUT_CSV_PATH = \"preprocessed_brewery_data_balanced.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22ddc91-e7fc-4b08-a43e-95b18acae615",
   "metadata": {},
   "source": [
    "## Define column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c45672cb-0f21-4eed-950c-41c67e070f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_COLUMNS = ['Gravity', 'Alcohol_Content', 'pH_Level', 'Moisture_Content', 'Temperature']\n",
    "BRIX_COLUMN_NAME = 'Gravity'         # This is the original column name for Specific Gravity\n",
    "ALCOHOL_COLUMN_NAME = 'Alcohol_Content'\n",
    "PH_COLUMN_NAME = 'pH_Level'\n",
    "MOISTURE_COLUMN_NAME = 'Moisture_Content'\n",
    "TEMP_COLUMN_NAME = 'Temperature'\n",
    "TARGET_COLUMN_NAME = 'Fermentation_Status'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ef701f-8c59-44c4-9216-48507f9cb4f7",
   "metadata": {},
   "source": [
    "## For reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d856677c-c972-4aed-bd6d-ceea3c83f2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a614099-f40a-48d4-b193-b87a08b06541",
   "metadata": {},
   "source": [
    "## Load Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f51ca763-f667-4ffe-b071-4da42972921a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading Raw Data from: brewery_data_complete_extended.csv ---\n",
      "Successfully loaded 100000 rows.\n"
     ]
    }
   ],
   "source": [
    "print(f\"--- Loading Raw Data from: {CSV_FILE_PATH} ---\")\n",
    "try:\n",
    "    df = pd.read_csv(CSV_FILE_PATH, nrows=N_ROWS_TO_LOAD)\n",
    "    print(f\"Successfully loaded {len(df)} rows.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: File '{CSV_FILE_PATH}' not found. Creating a dummy DataFrame for demonstration.\")\n",
    "    data = {\n",
    "        'Batch_ID': range(N_ROWS_TO_LOAD),\n",
    "        BRIX_COLUMN_NAME: np.random.uniform(1.020, 1.090, N_ROWS_TO_LOAD), # SG\n",
    "        ALCOHOL_COLUMN_NAME: np.random.uniform(3.0, 8.0, N_ROWS_TO_LOAD),\n",
    "        PH_COLUMN_NAME: np.random.uniform(4.0, 6.0, N_ROWS_TO_LOAD),\n",
    "        TEMP_COLUMN_NAME: np.random.uniform(10.0, 30.0, N_ROWS_TO_LOAD),\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    print(\"Dummy DataFrame created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7beb59b0-2b0c-489e-917c-1ce560d93020",
   "metadata": {},
   "source": [
    "## Simulate Moisture Content (if not present)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd289a2e-9735-4814-8b7a-3d40f23ef39e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Simulating 'Moisture_Content' ---\n"
     ]
    }
   ],
   "source": [
    "if MOISTURE_COLUMN_NAME not in df.columns:\n",
    "    print(f\"\\n--- Simulating '{MOISTURE_COLUMN_NAME}' ---\")\n",
    "    df[MOISTURE_COLUMN_NAME] = np.random.uniform(low=85.0, high=95.0, size=len(df)) - \\\n",
    "                               (df[ALCOHOL_COLUMN_NAME] * 0.1 if ALCOHOL_COLUMN_NAME in df.columns else 0)\n",
    "    df[MOISTURE_COLUMN_NAME] = df[MOISTURE_COLUMN_NAME].round(2)\n",
    "    # Add some NaNs for imputation demonstration later\n",
    "    nan_indices = df.sample(frac=0.05, random_state=42).index\n",
    "    df.loc[nan_indices, MOISTURE_COLUMN_NAME] = np.nan\n",
    "else:\n",
    "    print(f\"\\n--- Using existing '{MOISTURE_COLUMN_NAME}' column ---\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef624208-8d48-4a21-bc8c-efaa57b6776d",
   "metadata": {},
   "source": [
    "## Convert Specific Gravity to Brix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "515f0c7e-b09e-4a84-8466-7c8ab0ee4f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Converting 'Gravity' (Specific Gravity) to Brix scale ---\n",
      "Conversion complete. Column 'Gravity' now contains Brix values.\n"
     ]
    }
   ],
   "source": [
    "if BRIX_COLUMN_NAME in df.columns:\n",
    "    print(f\"\\n--- Converting '{BRIX_COLUMN_NAME}' (Specific Gravity) to Brix scale ---\")\n",
    "    df[BRIX_COLUMN_NAME] = pd.to_numeric(df[BRIX_COLUMN_NAME], errors='coerce')\n",
    "    df = df.dropna(subset=[BRIX_COLUMN_NAME]) # Drop rows where Gravity couldn't be converted to numeric\n",
    "\n",
    "    # Replace 0 with NaN before division to avoid errors and handle them\n",
    "    df[BRIX_COLUMN_NAME] = df[BRIX_COLUMN_NAME].replace(0, np.nan)\n",
    "    df.dropna(subset=[BRIX_COLUMN_NAME], inplace=True) # Remove rows where Gravity was 0\n",
    "\n",
    "    if not df.empty: # Proceed only if DataFrame is not empty after NaN drops\n",
    "        sg = df[BRIX_COLUMN_NAME]\n",
    "        # Your provided formula for Brix from SG\n",
    "        df[BRIX_COLUMN_NAME] = (28.14203 * sg) + 202.4427 - (230.5870 / sg)\n",
    "        df[BRIX_COLUMN_NAME] = df[BRIX_COLUMN_NAME].round(2)\n",
    "        print(f\"Conversion complete. Column '{BRIX_COLUMN_NAME}' now contains Brix values.\")\n",
    "        # print(f\"First 5 converted Brix values:\\n{df[BRIX_COLUMN_NAME].head()}\")\n",
    "    else:\n",
    "        print(f\"DataFrame became empty after trying to clean '{BRIX_COLUMN_NAME}' for Brix conversion. Halting.\")\n",
    "        # raise SystemExit(\"Halting due to data issue in Brix conversion.\") # Optional: halt execution\n",
    "else:\n",
    "    print(f\"Warning: Column '{BRIX_COLUMN_NAME}' (expected for Gravity) not found for Brix conversion.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45aca632-d37d-4be0-b329-9205d889759d",
   "metadata": {},
   "source": [
    "## Ensure all feature columns exist, fill with NaN if created new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "78b77170-f5d2-4286-9f75-b7e4249db1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in FEATURE_COLUMNS:\n",
    "    if col not in df.columns:\n",
    "        print(f\"Warning: Feature column '{col}' was not in the original CSV or created. Adding as NaN.\")\n",
    "        df[col] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defcb446-9238-480e-b4e3-abb873859353",
   "metadata": {},
   "source": [
    "## Select only the feature columns we intend to process further + any ID columns if needed later\n",
    "## For simplicity, we'll just work with the defined FEATURE_COLUMNS from now on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4d93f8da-9a7b-47a6-979d-fb0e4ed2b13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = df[FEATURE_COLUMNS].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7b54fc-ff04-4cd8-abd0-c09dba1a48e6",
   "metadata": {},
   "source": [
    "## Handle Data Types and Coercion for all feature columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1bbde0d7-a4de-4bec-8ba9-75614fcdfab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Handling Data Types for Feature Columns ---\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n--- Handling Data Types for Feature Columns ---\")\n",
    "def clean_feature_value(value):\n",
    "    if isinstance(value, str):\n",
    "        for delim in ['-', '/', ' ', '_']:\n",
    "            if delim in value: value = value.split(delim)[0]\n",
    "        value = ''.join(c for c in str(value) if c.isdigit() or c == '.')\n",
    "        parts = value.split('.')\n",
    "        if len(parts) > 2: value = parts[0] + '.' + parts[1]\n",
    "    try: return float(value)\n",
    "    except (ValueError, TypeError): return np.nan\n",
    "\n",
    "for col in FEATURE_COLUMNS:\n",
    "    if col in df_features.columns:\n",
    "        if df_features[col].dtype == 'object': # If it's still an object type\n",
    "            print(f\"Applying string cleaning to object column {col}...\")\n",
    "            df_features[col] = df_features[col].apply(clean_feature_value)\n",
    "        # Final explicit conversion to numeric, coercing errors\n",
    "        df_features[col] = pd.to_numeric(df_features[col], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0507ebb-a2f9-4c0d-8cfe-2198c9fa2295",
   "metadata": {},
   "source": [
    "## Handle Missing Values (Median Imputation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2285779b-b737-4076-b632-5ad46f6bd9c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Handling Missing Values (Median Imputation) ---\n",
      "Imputed NaNs in 'Moisture_Content' with median 89.47.\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n--- Handling Missing Values (Median Imputation) ---\")\n",
    "for col in FEATURE_COLUMNS:\n",
    "    if col in df_features.columns and df_features[col].isnull().any():\n",
    "        median_val = df_features[col].median()\n",
    "        df_features[col] = df_features[col].fillna(median_val)\n",
    "        print(f\"Imputed NaNs in '{col}' with median {median_val:.2f}.\")\n",
    "# Drop any rows that are still all NaN across features (should be rare after imputation)\n",
    "df_features.dropna(how='all', inplace=True)\n",
    "df = df.loc[df_features.index].copy() # Align original df if rows were dropped (e.g. if a whole feature column was NaN)\n",
    "df[FEATURE_COLUMNS] = df_features[FEATURE_COLUMNS] # Update df with cleaned features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9373102-2667-4a59-9081-52617bdd2719",
   "metadata": {},
   "source": [
    "## IQR Outlier Capping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "85f69269-81aa-4ec0-9324-d4a89bb0790e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Applying IQR Outlier Capping ---\n",
      "IQR outlier capping complete.\n",
      "\n",
      "Descriptive statistics after outlier capping:\n",
      "             Gravity  Alcohol_Content       pH_Level  Moisture_Content  \\\n",
      "count  100000.000000    100000.000000  100000.000000     100000.000000   \n",
      "mean       13.521659         5.251379       5.000560         89.466125   \n",
      "std         3.398580         0.433797       0.288597          2.812281   \n",
      "min         7.560000         4.500014       4.500001         84.410000   \n",
      "25%        10.590000         4.873972       4.751442         87.090000   \n",
      "50%        13.560000         5.252499       5.001072         89.470000   \n",
      "75%        16.480000         5.627443       5.251072         91.830000   \n",
      "max        19.330000         5.999956       5.499992         94.550000   \n",
      "\n",
      "         Temperature  \n",
      "count  100000.000000  \n",
      "mean       20.019249  \n",
      "std         2.886794  \n",
      "min        15.000089  \n",
      "25%        17.518969  \n",
      "50%        20.030475  \n",
      "75%        22.505320  \n",
      "max        24.999868  \n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n--- Applying IQR Outlier Capping ---\")\n",
    "for col in FEATURE_COLUMNS:\n",
    "    if col in df.columns and pd.api.types.is_numeric_dtype(df[col]):\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        df[col] = np.where(df[col] < lower_bound, lower_bound, df[col])\n",
    "        df[col] = np.where(df[col] > upper_bound, upper_bound, df[col])\n",
    "print(\"IQR outlier capping complete.\")\n",
    "print(\"\\nDescriptive statistics after outlier capping:\")\n",
    "print(df[FEATURE_COLUMNS].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308f07f3-2b8b-4805-b130-a78d97273627",
   "metadata": {},
   "source": [
    "## Simulate Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "61e94b03-421f-4e64-a203-d1abe10ea25f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Simulating Target Variable 'Fermentation_Status' ---\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n--- Simulating Target Variable '{TARGET_COLUMN_NAME}' ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d97e10-6b46-4bbf-aa6c-6382f5b374db",
   "metadata": {},
   "source": [
    "## Ensure key columns for simulation are numeric and handle any NaNs that might stop the rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "69477d47-3fb2-4e8f-93a7-59652fbf2841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target variable distribution BEFORE balancing:\n",
      "Fermentation_Status\n",
      "0    0.98124\n",
      "1    0.01876\n",
      "Name: proportion, dtype: float64\n",
      "Fermentation_Status\n",
      "0    98124\n",
      "1     1876\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df[ALCOHOL_COLUMN_NAME] = pd.to_numeric(df[ALCOHOL_COLUMN_NAME], errors='coerce')\n",
    "df[BRIX_COLUMN_NAME] = pd.to_numeric(df[BRIX_COLUMN_NAME], errors='coerce') # Already Brix values\n",
    "df.dropna(subset=[ALCOHOL_COLUMN_NAME, BRIX_COLUMN_NAME], inplace=True) # Critical for reliable simulation\n",
    "\n",
    "if df.empty:\n",
    "    print(\"ERROR: DataFrame is empty after ensuring simulation columns are clean. Cannot create target.\")\n",
    "else:\n",
    "    # **ADJUST THIS RULE BASED ON YOUR BRIX SCALE AND DESIRED BALANCE BEFORE UNDERSAMPLING**\n",
    "    # Example: Target '1' (Ready) if Alcohol > 5.2 AND Brix (in 'Gravity' col) < 8.0\n",
    "    # This rule needs to generate a reasonable number of '1's to make balancing meaningful.\n",
    "    df[TARGET_COLUMN_NAME] = 0\n",
    "    ready_condition = (df[ALCOHOL_COLUMN_NAME] > 5.2) & (df[BRIX_COLUMN_NAME] < 8.0)\n",
    "    df.loc[ready_condition, TARGET_COLUMN_NAME] = 1\n",
    "    \n",
    "    print(\"\\nTarget variable distribution BEFORE balancing:\")\n",
    "    print(df[TARGET_COLUMN_NAME].value_counts(normalize=True))\n",
    "    print(df[TARGET_COLUMN_NAME].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528ae0b6-234f-4769-a317-7f5ebd6aa8de",
   "metadata": {},
   "source": [
    "## Balance Dataset (Undersampling Majority)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5aa2f404-c107-439d-be39-57c7d8716b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Balancing Dataset for 'Fermentation_Status' ---\n",
      "Undersampling majority class (0) from 98124 to match minority class (1) of 1876 samples.\n",
      "\n",
      "Target variable distribution AFTER balancing:\n",
      "Fermentation_Status\n",
      "0    0.5\n",
      "1    0.5\n",
      "Name: proportion, dtype: float64\n",
      "Fermentation_Status\n",
      "0    1876\n",
      "1    1876\n",
      "Name: count, dtype: int64\n",
      "Total samples in balanced dataset: 3752\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n--- Balancing Dataset for '{TARGET_COLUMN_NAME}' ---\")\n",
    "if TARGET_COLUMN_NAME not in df.columns or df[TARGET_COLUMN_NAME].nunique() < 2 :\n",
    "     print(f\"Target column '{TARGET_COLUMN_NAME}' not found or has only one class. Skipping balancing.\")\n",
    "     df_balanced = df.copy() # Use the df as is if target is problematic\n",
    "elif df.empty:\n",
    "    print(\"DataFrame is empty before balancing. Skipping.\")\n",
    "    df_balanced = df.copy()\n",
    "else:\n",
    "    df_majority = df[df[TARGET_COLUMN_NAME] == 0]\n",
    "    df_minority = df[df[TARGET_COLUMN_NAME] == 1]\n",
    "\n",
    "    if len(df_minority) == 0:\n",
    "        print(\"ERROR: Minority class (1) has 0 samples. Cannot balance by undersampling. Saving as is.\")\n",
    "        df_balanced = df.copy()\n",
    "    elif len(df_majority) == 0:\n",
    "        print(\"ERROR: Majority class (0) has 0 samples. Data is already 100% minority. Saving as is.\")\n",
    "        df_balanced = df.copy()\n",
    "    elif len(df_majority) == len(df_minority):\n",
    "        print(\"Dataset is already balanced.\")\n",
    "        df_balanced = df.copy()\n",
    "    else:\n",
    "        print(f\"Undersampling majority class (0) from {len(df_majority)} to match minority class (1) of {len(df_minority)} samples.\")\n",
    "        df_majority_downsampled = resample(df_majority,\n",
    "                                         replace=False,\n",
    "                                         n_samples=len(df_minority),\n",
    "                                         random_state=42)\n",
    "        df_balanced = pd.concat([df_majority_downsampled, df_minority])\n",
    "        \n",
    "        print(\"\\nTarget variable distribution AFTER balancing:\")\n",
    "        print(df_balanced[TARGET_COLUMN_NAME].value_counts(normalize=True))\n",
    "        print(df_balanced[TARGET_COLUMN_NAME].value_counts())\n",
    "        print(f\"Total samples in balanced dataset: {len(df_balanced)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b83973c-c761-4be9-900d-eda311f19e06",
   "metadata": {},
   "source": [
    "## Shuffle the balanced (or original if balancing failed/skipped) dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e27fdd2d-1921-4f0d-9bd4-6dec0225f919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame to be saved has 3752 rows.\n"
     ]
    }
   ],
   "source": [
    "df_to_save = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "print(f\"\\nDataFrame to be saved has {len(df_to_save)} rows.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172fdc9f-27bb-493a-ada2-aa470754e0bd",
   "metadata": {},
   "source": [
    "## Save Preprocessed and Balanced Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5fda1f85-df68-4121-9f0b-72851e23b074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Saving Preprocessed and Balanced Data to: preprocessed_brewery_data_balanced.csv ---\n",
      "\n",
      "Successfully saved data with 3752 rows and columns ['Gravity', 'Alcohol_Content', 'pH_Level', 'Moisture_Content', 'Temperature', 'Fermentation_Status'] to 'preprocessed_brewery_data_balanced.csv'.\n",
      "\n",
      "First 5 rows of the saved data:\n",
      "   Gravity  Alcohol_Content  pH_Level  Moisture_Content  Temperature  \\\n",
      "0     7.60         5.278893  5.365859             88.59    17.724930   \n",
      "1    16.33         5.758956  5.125840             84.89    15.695592   \n",
      "2     7.69         5.563351  4.732960             93.72    23.258060   \n",
      "3    11.56         4.658732  5.013984             86.96    16.272746   \n",
      "4     7.98         5.411103  4.784614             90.23    23.936993   \n",
      "\n",
      "   Fermentation_Status  \n",
      "0                    1  \n",
      "1                    0  \n",
      "2                    1  \n",
      "3                    0  \n",
      "4                    1  \n",
      "\n",
      "Final distribution in saved file:\n",
      "Fermentation_Status\n",
      "1    0.5\n",
      "0    0.5\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n--- Saving Preprocessed and Balanced Data to: {OUTPUT_CSV_PATH} ---\")\n",
    "columns_to_save = FEATURE_COLUMNS + [TARGET_COLUMN_NAME]\n",
    "# Ensure all columns exist in df_to_save before trying to select them\n",
    "final_columns_present = [col for col in columns_to_save if col in df_to_save.columns]\n",
    "\n",
    "if not df_to_save.empty and set(columns_to_save) <= set(df_to_save.columns):\n",
    "    df_final_output = df_to_save[final_columns_present]\n",
    "    try:\n",
    "        df_final_output.to_csv(OUTPUT_CSV_PATH, index=False)\n",
    "        print(f\"\\nSuccessfully saved data with {len(df_final_output)} rows and columns {df_final_output.columns.tolist()} to '{OUTPUT_CSV_PATH}'.\")\n",
    "        print(\"\\nFirst 5 rows of the saved data:\")\n",
    "        print(df_final_output.head())\n",
    "        print(\"\\nFinal distribution in saved file:\")\n",
    "        print(df_final_output[TARGET_COLUMN_NAME].value_counts(normalize=True))\n",
    "        if df_final_output[TARGET_COLUMN_NAME].nunique() < 2:\n",
    "            print(\"WARNING: The saved file still contains only one class for the target variable!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving preprocessed data: {e}\")\n",
    "else:\n",
    "    if df_to_save.empty:\n",
    "        print(\"\\nCould not save: DataFrame is empty.\")\n",
    "    else:\n",
    "        print(f\"\\nCould not save: Not all required columns ({columns_to_save}) are present in the DataFrame to be saved.\")\n",
    "        print(f\"Columns available: {df_to_save.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7c6664-0c76-4bcb-8d88-7883f222a525",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
